FORMAT: 1A

HOST: https://api.theysay.io/v1

# TheySay PreCeive API Documentation

TheySay PreCeive API is a platform-agnostic service which enables developers to access and mix-and-match our powerful text analysis processors that cover sentiment analysis, speculation detection, part-of-speech
tagging, dependency parsing, and others. If you're building an application that cannot do without serious, state-of-the-art text analytics but don't want to delve deep into natural language processing,
then this is the API for you.

Getting started with PreCeive API is easy. Test-drive our live public [API demo](http://apidemo.theysay.io), explore its end points below, and [contact us](mailto:contact@theysayanalytics.com?Subject=PreCeive%20API%20Development%20key%20request) to receive a development key. Need help or want to give feedback? [Contact us](mailto:contact@theysayanalytics.com?Subject=PreCeive%20API%20feedback) - we'd love to hear from you!

API Clients
------------
To help you get started, Open Source API clients are currently available for [Java (1)](https://github.com/theysay/affectr-java-client), [Java (2)](https://github.com/theysay/affectr-java-2), [Scala](https://github.com/theysay/affectr-scala-client), [Python](https://github.com/theysay/affectr-python-client), [Ruby](https://github.com/theysay/affectr-ruby), [Node.js](https://github.com/theysay/affectr-nodejs), [R](https://github.com/theysay/affectr-r), and [PHP](https://github.com/theysay/affectr-php). C# and Excel clients will be released soon.

Multilingual Support
--------------------
The API expects you to submit English text to it.
Beyond English, multilingual support is provided in the form of specific language-analysis pairs.
Multilingual support currently covers German sentiment analysis.

HTTP Methods
------------
PreCeive API follows [REST principles](http://en.wikipedia.org/wiki/Representational_state_transfer).
The following HTTP request methods are supported for analysis requests:

- `POST` (recommended)
  * Query fields are in the request body and expressed as JSON.
  * Example payload: `{ "text":"Patchy rain, sleet or snow in parts...", "level":"sentence" }`
- `GET` 
  * Query fields are expressed as parameters in the URL and must be URL-encoded. Note that `GET` exposes only a limited subset of available query fields.
  * Example URL: `/v1/sentiment?text=how%20cool%20is%20that!&level=sentence`

HTTP Response Codes
-------------------
- 200 `OK` - The request was successful.
- 201 `Created` - The request was successful and a resource was created.
- 400 `Bad Request` - The request could not be interpreted correctly or some required parameters were missing.
- 401 `Unauthorized` - Authentication failed - double-check your username and/or password.
- 405 `Method Not Allowed` - The requested method is not supported. Only GET and POST are allowed.
- 429 `Too Many Requests` - Quota or rate limit exceeded (see below).
- 500 `Internal Server Error` - Something is broken. Please contact us and we'll investigate.

Quotas and Rate Limits
-----
We enforce two request quotas: requests per day and requests per minute. Your quotas depend on your API subscription.
By default, the following rates apply:

* Maximum `500` requests per day, reset at midnight UTC.
* Maximum `30` requests per minute.

Responses returned by the API contain information about your quota in the following response header fields:

- `X-RequestLimit-Limit` - # of requests that you can send in a day. Example: `15000`.
- `X-RequestLimit-Remaining` - # of requests that you can send before you will exceed your daily request limit. Example: `12323`.
- `X-RequestLimit-Reset` - When your next daily quota will be reset (in UTC [epoch milliseconds](http://en.wikipedia.org/wiki/Unix_time)). Example: `1360281599708`.
- `X-RateLimit-IntervalSecs` - The length of your rate limit window. Example: `60`.
- `X-RateLimit-Limit` - # of requests that can send within your rate limit window. Example: `30`.
- `X-RateLimit-Remaining` - # of requests that you can send before you will exceed your rate limit. Example: `25`.
- `X-RateLimit-Reset` - When your next rate limit window will be reset (in UTC [epoch milliseconds](http://en.wikipedia.org/wiki/Unix_time)). Example: `1360254866709`.

You can also see your current rate limit status by calling `/rate_limit`. Example: [http://api.theysay.io/rate_limit](http://api.theysay.io/rate_limit).

For more information about quotas, rate limits, and subscriptions, [contact us](mailto:contact@theysayanalytics.com?Subject=PreCeive%20API%20rate-limit%20enquiry).

Maximum Request Length
-----
The maximum length of the text body in each request is `20000` characters.

JSONP Support
-------------
Use the `callback` request parameter to add a [JSONP](http://en.wikipedia.org/wiki/JSONP) wrapper. The returned `Content-Type` will be `application/javascript`.

GZIP Compression
----------------
Add `Accept-Encoding: gzip` to your request headers if you want the API to deliver a gzipped stream.

Server Version
--------------
To view build and version information about the current API, call `/version`. Example: [http://api.theysay.io/version](http://api.theysay.io/version)


## Sentiment Analysis: English [/sentiment]

Sentiment, a dimension of non-factuality in language that is closely related to subjectivity/affect/emotion/moods/feelings, reflects psychological evaluation with the following fundamental poles:

* `positive` (~ good / pros / favourable / desirable / recommended / thumbs up /...)
vs
* `negative` (~ bad / cons / unfavourable / undesirable / not recommended / thumbs down /...)

You can use the Sentiment Analysis service to discover and score deep, fine-grained sentiments and opinions in text.
The analysis, output by a human-like sentiment reasoning algorithm, captures both explicit "author sentiment" as well as
general, implicit "reader-sentiment" beyond opinions that ultimately stems from affective commons sense as well as issues and events that are
generally considered to be good vs. bad in the world.

The returned analysis includes majority sentiment labels, fine-grained 3-way positive/neutral/negative percentage scores,
and other useful auxiliary fields.

### Documents [POST]

Returns sentiment information about the entire text (document-level sentiment analysis).

+ Attributes (object)

    + text: ...your...text... (string, required) - The text that you want to analyse.
    + bias (object, optional) - Sentiment coefficient d (0 ≤ d ≤ 100) to control the (in)sensitivity of the sentiment analysis towards sentiment polarity p where p ∈ { positive | neutral | negative }).
        + positive: `3.5` (number, optional) - Positive sentiment coefficient.
        + neutral: `2.7` (number, optional) - Neutral sentiment coefficient.
        + negative: `18` (number, optional) - Negative sentiment coefficient.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        {
         "sentiment": {
          "label": "POSITIVE",
          "positive": 0.941,
          "negative": 0.0,
          "neutral": 0.059
         },
         "wordCount": 12
        }

### Sentences [POST]

Returns sentiment information about each sentence in the text (sentence-level sentiment analysis).

+ Attributes (object)

    + text: ...your...text... (string, required) - The text that you want to analyse.
    + level: `sentence` (string, required) - Enables sentence-level sentiment analysis.
    + bias (object, optional) - Sentiment coefficient d (0 ≤ d ≤ 100) to control the (in)sensitivity of the sentiment analysis towards sentiment polarity p where p ∈ { positive | neutral | negative }).
        + positive: `3.5` (number, optional) - Positive sentiment coefficient.
        + neutral: `2.7` (number, optional) - Neutral sentiment coefficient.
        + negative: `18` (number, optional) - Negative sentiment coefficient.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "sentiment": {
          "label": "POSITIVE",
          "positive": 0.787,
          "negative": 0.16,
          "neutral": 0.053,
          "confidence": 0.668
          },
          "start": 0,
          "end": 36,
          "sentenceIndex": 0,
          "text": "The new French President Francois Hollande wants a '' growth pact '' in Europe - a set of reforms designed to boost European economies and mitigate the pain caused by government spending cuts across the continent ."
        }, {
          "sentiment": {
          "label": "NEGATIVE",
          "positive": 0.347,
          "negative": 0.627,
          "neutral": 0.026,
          "confidence": 0.614
        },
          "start": 37,
          "end": 68,
          "sentenceIndex": 1,
          "text": "All the bad loans made by eurozone banks may need to be cleaned up ( by injecting money into the banks ) because many national governments probably can not afford it ."
        }]

### Entity Mentions [POST]

Returns sentiment information about each individual entity (term, keyword) mentioned in the text (entity-level sentiment analysis).

By default, all analysed entities are returned in the response.
If you want to control which entities are included in the response, use the `"targets"` and `"matching"` fields to specify which entities you want.
The `"targets"` field accepts a list of regular expressions delimited by the `|` (`%7C` encoded) operator.
Example: `"targets":"market"` or `"targets":"market|business(es)?|opportunity|cost"`

The specified target entities are matched against words in each entity NP using the following matching modes:

* `"matching":"head"` (or none) (default) - The targets match the head noun of an entity NP (full head match).
* `"matching":"exact"` - The targets match an entity NP (full match).
* `"matching":"phrase"` - The targets can match anywhere inside an entity NP (substring search).

+ Attributes (object)

    + text: ...your...text... (string, required) - The text that you want to analyse.
    + level: `entity` (string, required) - Enables entity-level sentiment analysis.
    + bias (object, optional) - Sentiment coefficient d (0 ≤ d ≤ 100) to control the (in)sensitivity of the sentiment analysis towards sentiment polarity p where p ∈ { positive | neutral | negative }).
        + positive: `3.5` (number, optional) - Positive sentiment coefficient.
        + neutral: `2.7` (number, optional) - Neutral sentiment coefficient.
        + negative: `18` (number, optional) - Negative sentiment coefficient.
    + targets: market|business|opportunity|cost (string, optional) - Match expression for target entities.
    + matching: head - Matching mode.
    
+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "sentiment": {
            "label": "POSITIVE",
            "positive": 1.0,
            "negative": 0.0,
            "neutral": 0.0,
            "confidence": 0.756
          },
          "start": 2,
          "end": 2,
          "sentence": "'' This collaboration is sending a strong message to all the spammers : Stop sending us spam .",
          "sentenceHtml": "'' This <span class=\"entityMention\">collaboration</span> is sending a strong message to all the spammers : Stop sending us spam .",
          "text": "collaboration",
          "headNoun": "collaboration",
          "headNounIndex": 2,
          "salience": 1.0
        }, {
          "sentiment": {
            "label": "NEGATIVE",
            "positive": 0.412,
            "negative": 0.588,
            "neutral": 0,
            "confidence": 0.689
          },
          "start": 11,
          "end": 11,
          "sentence": "'' This collaboration is sending a strong message to all the spammers : Stop sending us spam .",
          "sentenceHtml": "'' This collaboration is sending a strong message to all the <span class=\"entityMention\">spammers</span> : Stop sending us spam .",
          "text": "spammers",
          "headNoun": "spammers",
          "headNounIndex": 11,
          "salience": 0.7
        }]

### Entity Aggregates [POST]

Returns sentiment information about aggregated entities (terms, keywords) mentioned in the text. Individual entity mentions are grouped using lowercase head noun matching and scored using weighted sentiment scores.

+ Attributes (object)

    + text: ...your...text... (string, required) - The text that you want to analyse.
    + level: `entityaggregate` (string, required) - Enables sentiment analysis for entity aggregates.
    + bias (object, optional) - Sentiment coefficient d (0 ≤ d ≤ 100) to control the (in)sensitivity of the sentiment analysis towards sentiment polarity p where p ∈ { positive | neutral | negative }).
        + positive: `3.5` (number, optional) - Positive sentiment coefficient.
        + neutral: `2.7` (number, optional) - Neutral sentiment coefficient.
        + negative: `18` (number, optional) - Negative sentiment coefficient.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "entity": "osborne",
          "frequency": 2,
          "sentiment": {
            "label": "NEGATIVE",
            "positive": 0.0,
            "negative": 0.96,
            "neutral": 0.04,
            "confidence": 0.801
          },
          "salience": 1.0,
          "mentions": [{
            "sentiment": {
              "label": "NEGATIVE",
              "positive": 0.0,
              "negative": 0.851,
              "neutral": 0.149,
              "confidence": 0.775
            },
            "start": 0,
            "end": 1,
            "sentence": "Mr Osborne said the banking system was not working for its customers .",
            "sentenceHtml": " <span class=\"entityMention\">Mr Osborne</span> said the banking system was not working for its customers .",
            "text": "Mr Osborne",
            "headNoun": "Osborne",
            "headNounIndex": 1,
            "salience": 1.0
          }, {
           "sentiment": {
             "label": "NEGATIVE",
             "positive": 0.0,
             "negative": 0.861,
             "neutral": 0.139,
             "confidence": 0.827
           },
           "start": 13,
           "end": 13,
           "sentence": "Osborne also said that banks had failed to take responsibility for their actions .",
           "sentenceHtml": " <span class=\"entityMention\">Osborne</span> also said that banks had failed to take responsibility for their actions .",
           "text": "Osborne",
           "headNoun": "Osborne",
           "headNounIndex": 13,
           "salience": 1.0
          }]
        }]

### Entity Relations [POST]

Returns sentiment information about detailed relations between entities (terms, keywords) mentioned in the text.

+ Attributes (object)

    + text: ...your...text... (string, required) - The text that you want to analyse.
    + level: `entityrelation` (string, required) - Enables relational entity-level sentiment analysis.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "entity1": {
            "head": "Avanesov",
            "headIndex": 2,
            "text": "Russian Georgiy Avanesov"
          },
          "entity2": {
            "head": "botnet",
            "headIndex": 17,
            "text": "Bredolab botnet"
          },
          "sentiment": {
            "label": "NEGATIVE",
            "positive": 0.209,
            "negative": 0.523,
            "neutral": 0.268
          },
          "salience": 0.243,
          "sentence": "Russian Georgiy Avanesov was in May sentenced to four years in jail for being behind the Bredolab botnet which was believed to have been generating more than # 80,000 a month in revenue .",
          "sentenceHtml": " <span class=\"entity1\">Russian Georgiy Avanesov</span> was in May sentenced to four years in jail for being behind the <span class=\"entity2\">Bredolab botnet</span> which was believed to have been generating more than # 80,000 a month in revenue ."
          }, {
            "entity1": {
            "head": "Avanesov",
            "headIndex": 2,
            "text": "Russian Georgiy Avanesov"
          },
          "entity2": {
            "head": "revenue",
            "headIndex": 32,
            "text": "revenue"
          },
          "sentiment": {
            "label": "POSITIVE",
            "positive": 0.377,
            "negative": 0.314,
            "neutral": 0.309
          },
          "salience": 0.155,
          "sentence": "Russian Georgiy Avanesov was in May sentenced to four years in jail for being behind the Bredolab botnet which was believed to have been generating more than # 80,000 a month in revenue .",
          "sentenceHtml": " <span class=\"entity1\">Russian Georgiy Avanesov</span> was in May sentenced to four years in jail for being behind the Bredolab botnet which was believed to have been generating more than # 80,000 a month in <span class=\"entity2\">revenue</span> ."
        }]

### Sentiment Flow in Text [POST]

Returns information about the flow of sentiment through the text (document-level sentiment timeline analysis).
The analysis covers contextual sentence-level sentiment labels and positional co-ordinates for individual words in the text which you can use to plot the temporal development (or flow) of sentiment through the text.

+ Attributes (object)

    + text: ...your...text... (string, required) - The text that you want to analyse.
    + level: `word` (string, required) - Enables document-level sentiment flow analysis.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "sentiment": {
            "label": "NEGATIVE",
            "timelineY": -1.0
          },
          "wordIndex": 0,
          "text": "There"
          }, {
          "sentiment": {
            "label": "NEGATIVE",
            "timelineY": -1.004
          },
          "wordIndex": 1,
          "text": "have"
          }, {
          "sentiment": {
            "label": "NEGATIVE",
            "timelineY": -1.008
          },
          "wordIndex": 2,
          "text": "been"
          }, {
          "sentiment": {
            "label": "NEGATIVE",
            "timelineY": -1.012
          },
          "wordIndex": 3,
          "text": "clashes"
          }, {
          "sentiment": {
            "label": "NEGATIVE",
            "timelineY": -1.0170000000000001
          },
          "wordIndex": 4,
          "text": "throughout"
          }, {
          "sentiment": {
            "label": "NEGATIVE",
            "timelineY": -1.0210000000000001
          },
          "wordIndex": 5,
          "text": "the"
          }, {
          "sentiment": {
            "label": "NEGATIVE",
            "timelineY": -1.025
          },
          "wordIndex": 6,
          "text": "night"
          }, {
          "sentiment": {
            "label": "NEGATIVE",
            "timelineY": -1.029
          },
          "wordIndex": 7,
          "text": "in"
          }, {
          "sentiment": {
            "label": "NEGATIVE",
            "timelineY": -1.033
          },
          "wordIndex": 8,
          "text": "many"
          }, {
          "sentiment": {
            "label": "NEGATIVE",
            "timelineY": -1.037
          },
          "wordIndex": 9,
          "text": "parts"
          }, {
          "sentiment": {
            "label": "NEGATIVE",
            "timelineY": -1.042
          },
          "wordIndex": 10,
          "text": "of"
          }, {
          "sentiment": {
            "label": "NEGATIVE",
            "timelineY": -1.046
          },
          "wordIndex": 11,
          "text": "Syria"
          }, {
          "sentiment": {
            "label": "NEUTRAL",
            "timelineY": -1.046
          },
          "wordIndex": 12,
          "text": "."
        }]

## Sentiment Analysis: Multilingual [/multilingual/sentiment]

Beyond English, the API offers sentiment analysis for German (language code `de`) at the document and the sentence levels.

## Documents [POST]

Returns sentiment information about the entire text (document-level sentiment analysis).

+ Attributes (object)

    + text: ...your...text... (string, required) - The text that you want to analyse.
    + language: `de` (string, required) - The ISO 639-1 natural language code for the input text. See http://www.loc.gov/standards/iso639-2/php/code_list.php for the codes.
    + bias (object, optional) - Sentiment coefficient d (0 ≤ d ≤ 100) to control the (in)sensitivity of the sentiment analysis towards sentiment polarity p where p ∈ { positive | neutral | negative }).
        + positive: `3.5` (number, optional) - Positive sentiment coefficient.
        + neutral: `2.7` (number, optional) - Neutral sentiment coefficient.
        + negative: `18` (number, optional) - Negative sentiment coefficient.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        {
         "sentiment": {
          "label": "POSITIVE",
          "positive": 0.941,
          "negative": 0.0,
          "neutral": 0.059
         },
         "wordCount": 12
        }

### Sentences [POST]

Returns sentiment information about each sentence in the text (sentence-level sentiment analysis).

+ Attributes (object)

    + text: ...your...text... (string, required) - The text that you want to analyse.
    + level: `sentence` (string, required) - Enables sentence-level sentiment analysis.
    + language: `de` (string, required) - The ISO 639-1 natural language code for the input text. See http://www.loc.gov/standards/iso639-2/php/code_list.php for the codes.
    + bias (object, optional) - Sentiment coefficient d (0 ≤ d ≤ 100) to control the (in)sensitivity of the sentiment analysis towards sentiment polarity p where p ∈ { positive | neutral | negative }).
        + positive: `3.5` (number, optional) - Positive sentiment coefficient.
        + neutral: `2.7` (number, optional) - Neutral sentiment coefficient.
        + negative: `18` (number, optional) - Negative sentiment coefficient.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "sentiment": {
            "label": "NEGATIVE",
            "positive": 0.147,
            "negative": 0.778,
            "neutral": 0.076
          },
          "start": 0,
          "end": 14,
          "sentenceIndex": 0,
          "text": "Rund 70 Flüchtlinge haben in Heidenau gegen die schlechten Bedingungen in ihrer Unterkunft protestiert ."
        },{
          "sentiment": {
            "label": "NEGATIVE",
            "positive": 0.256,
            "negative": 0.573,
            "neutral": 0.17
          },
          "start": 15,
          "end": 22,
          "sentenceIndex": 1,
          "text": "USA bereiten sich auf 10.000 syrische Flüchtlinge vor"
        }]

## Emotion Analysis [/emotion]

Beyond positive vs. negative sentiment polarity, a vast range of psychological dimensions exist in the realm of emotions/moods/feelings/affect.
You can use the Emotion Analysis service to project the text onto a fine-grained, multi-dimensional emotion space which is more natural than a singular majority label.
The returned analysis lists emotion dimension labels, each with a confidence value from the prediction, and covers the following basic unbounded emotion dimensions:

* `anger1D` - 1-dimensional anger scale (> 0).
* `fear1D` - 1-dimensional fear scale (> 0).
* `shame1D` - 1-dimensional shame scale (> 0).
* `surprise1D` - 1-dimensional surprise scale (> 0).
* `calm2D` - 2-dimensional scale between calmness (> 0) vs. agitation (< 0).
* `happy2D` - 2-dimensional scale between happiness (> 0) vs. sadness (< 0).
* `like2D` - 2-dimensional scale between liking (> 0) vs. disliking/disgust (< 0).
* `sure2D` - 2-dimensional scale between certainty/sureness (> 0) vs. uncertainty/unsureness (< 0).

### Documents [POST]

Returns emotion dimensions for the entire input text (document-level emotion analysis).

+ Attributes (object)

    + text: ...your...text... (string, required) - The text that you want to analyse.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        {
          "emotions": [
            {
              "dimension": "anger1D",
              "score": 1.667
            },
            {
              "dimension": "calm2D",
              "score": -0.478
            },
            {
              "dimension": "fear1D",
              "score": 0
            },
            {
              "dimension": "happy2D",
              "score": 0
            },
            {
              "dimension": "like2D",
              "score": -1.4
            },
            {
              "dimension": "shame1D",
              "score": 0
            },
            {
              "dimension": "sure2D",
              "score": -0.667
            },
            {
              "dimension": "surprise1D",
              "score": 0
            }
        ]}

### Sentences [POST]

Returns emotion dimensions for each sentence in the input text (sentence-level emotion analysis).

+ Attributes (object)

    + text: ...your...text... (string, required) - The text that you want to analyse.
    + level: `sentence` (string, required) - Enables sentence-level emotion analysis.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
            "emotions": [
              {
                "dimension": "anger1D",
                "score": 5
              },
              {
                "dimension": "calm2D",
                "score": -3.9
              },
              {
                "dimension": "fear1D",
                "score": 0
              },
              {
                "dimension": "happy2D",
                "score": 0
              },
              { 
                "dimension": "like2D",
                "score": -2.533
              },
              {
                "dimension": "shame1D",
                "score": 0
              },
              {
                "dimension": "sure2D",
                "score": 0
              },
              {
                "dimension": "surprise1D",
                "score": 0
              }
            ],
            "start": 11,
            "end": 23,
            "sentenceIndex": 1,
            "text": "I have been called vile , villainous and evil for criticising her ."
          },
          {
            "emotions": [
              {
                "dimension": "anger1D",
                "score": 1.071
              },
              {
                "dimension": "calm2D",
                "score": -0.943
              },
              {
                "dimension": "fear1D",
                "score": 0.714
              },
              {
                "dimension": "happy2D",
                "score": -1.175
              },
              {
                "dimension": "like2D",
                "score": -0.536
              },
              {
                "dimension": "shame1D",
                "score": 0
              },
              {
                "dimension": "sure2D",
                "score": -0.286
              },
              {
                "dimension": "surprise1D",
                "score": 0.286
              }
            ],
            "start": 14,
            "end": 24,
            "sentenceIndex": 1,
            "text": "I wonder how many times she cried and considered suicide ."
        }]


## Speculation Detection [/speculation]

Speculative language describes or refers directly or indirectly to irrealis events that are yet to happen.
Speculative expressions can hence cover concepts as diverse as future, certainty, doubt, prediction, wanting, wishes, and waiting, to name a few.
This service detects speculative expressions at the sentence level.
The response contains only 'positive' matches: if no speculative content is detected, the response is `[]`, accordingly.
Any identified subtypes of speculation are denoted with the dot operator (`.`) (e.g. `SPECULATION.SUBTYPE`).

### Sentences [POST]

+ Attributes (object)

    + text: It's probably not advisable to use it. (string, required) - The text that you want to analyse.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "start": 0,
          "end": 8,
          "sentenceIndex": 0,
          "speculationType": "SPECULATION.ADVICE",
          "text": "It 's probably not advisable to use it ."
        }]


## Risk Detection [/risk]

This sentence-level service detects expressions that describe or refer to risk and danger, either directly or indirectly.
The response contains only 'positive' matches: if no risk expressions are detected, the response is hence `[]`.
Any identified subtypes of risk are denoted with the dot operator (`.`) (e.g. `RISK.SUBTYPE`).

### Sentences [POST]

+ Attributes (object)

    + text: Your plan sounds plain dangerous in my mind. (string, required) - The text that you want to analyse.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "start": 0,
          "end": 8,
          "sentenceIndex": 0,
          "riskType": "RISK",
          "text": "Your plan sounds plain dangerous in my mind."
        }]


## Intent Detection [/intent]

This sentence-level service detects expressions pertaining to intent, intentions, plans, and decisions that can be detected in text.
The response contains only 'positive' matches: if no intent expressions are detected, the response is `[]`.
Any identified subtypes of intent are denoted with the dot operator (`.`) (e.g. `INTENT.SUBTYPE`).

### Sentences [POST]

+ Attributes (object)

    + text: I have made a decision to purchase the new improved camera model. (string, required) - The text that you want to analyse.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "start": 0,
          "end": 11,
          "sentenceIndex": 0,
          "intentType": "INTENT.DECISION",
          "text": "I have made a decision to purchase the new improved camera model."
        }]


## Gender Classification [/gender]

This end point allows you to predict the gender of the author who wrote the text.
The prediction is based solely on the text itself - no user profile information is considered.
The returned analysis offers gender labels (`MALE` vs. `FEMALE`) as well as confidence values from the predictions.

### Author Gender [POST]

Returns a gender prediction for the entire input text (document-level gender detection).

+ Attributes (object)

    + text: He likes to drink beer and watch football with his mates. (string, required) - The text that you want to analyse.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        {
          "score": {
            "label": "MALE",
            "confidence": 0.513
          }
        }

## Humour Detection [/humour]

A great many charged sentiment expressions express humour as is evidenced by jokes; puns and word play; funny anecdotes, stories, proverbs, and sayings; one-liners, spoonerisms, and other highly creative linguistic devices.
You can use the Humour Detection service to discover explitic and implicit humour(ous) signals in text.
The returned analysis offers humour type labels (`HUMOUR` vs. `NOT_HUMOUR`) as well as confidence values from the predictions.
Have fun!

### Document [POST]

Returns a humour prediction for the entire input text (document-level humour detection).

+ Attributes (object)

    + text: What do you get when you cross a lawyer with the Godfather? An offer you can't understand. (string, required) - The text that you want to analyse.
    
+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        {
          "score": {
             "label": "HUMOUR",
             "confidence": 0.941
          }
        }

### Sentences [POST]

Returns humour predictions for each sentence in the input text (sentence-level humour detection).

+ Attributes (object)

    + text: ...your...text... (string, required) - The text that you want to analyse.
    + level: `sentence` (string, required) - Enables sentence-level humour labels.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "score": {
            "label": "NOT_HUMOUR",
            "confidence": 0.763
          },
          "start": 64,
          "end": 90,
          "sentenceIndex": 3,
          "text": "The company said that the share award scheme is a one-off opportunity, but if it was successful, awards to employees would increase in the future."
        }, {
          "score": {
            "label": "HUMOUR",
            "confidence": 0.816
          },
          "start": 91,
          "end": 103,
          "sentenceIndex": 4,
          "text": "Shares will mainly be awarded to workers working in the \"famous chocolate factory\"... if u know wot i meen"
        }]


## Advertisement Classification [/ad]

Due to the fact that advertisements are spammy and almost invariably positive, they can skew sentiment measurements in a harmful way.
This service allows you to detect texts that are or resemble advertisements.
The returned analysis offers advertisement type labels (`AD` vs. `NOT_AD`) as well as confidence values from the predictions.

### Advertisements [POST]

Returns an advertisement prediction for the entire input text (document-level advertisement detection).

+ Attributes (object)

    + text: Get a one year subscription of this publication read by thousands of professionals and executives for the price of one year – just $29. Quickly while offer lasts! (string, required) - The text that you want to analyse.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        {
          "score": {
            "label": "AD",
            "confidence": 1
          }
        }


## Comparison Detection [/comparison]

This sentence-level service detects comparative expressions.
The response contains only 'positive' matches: if no comparative expressions are detected, the response is `[]`.
Any identified finer-grained comparative expressions are denoted with the dot operator (`.`) (e.g. `COMPARISON.SUBTYPE`).

### Sentences [POST]

+ Attributes (object)

    + text: Scala is much better than any other programming language. (string, required) - The text that you want to analyse.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "start": 0,
          "end": 9,
          "sentenceIndex": 0,
          "comparisonType": "COMPARISON",
          "text": "Scala is much better than any other programming language ."
        }]


## Named Entity Tagging [/namedentity]
This service detects expressions in the text snippet that refer explicitly or implicitly to

* people and humans in general (`PEOPLE`)
* places and locations (`LOCATION`)
* organisations and companies (`ORGANISATION`)
* times and dates (`TIMEDATE`)
* monetary issues (`MONEY`)

For each identified expression (which can be a simple or complex Noun Phrase, Adjective Phrase, or Adverb Phrase), the detected Named Entity types are ranked by their salience (most salient first).

### Named Entities [POST]

+ Attributes (object)

    + text: ...your...text... (string, required) - The text that you want to analyse.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "head": "Hollande",
          "headIndex": 5,
          "start": 0,
          "end": 5,
          "sentence": "The new French President Francois Hollande wants a '' growth pact '' in Europe - a set of reforms designed to boost European economies and mitigate the pain caused by government spending cuts across the continent .",
          "sentenceHtml": "The new French President Francois Hollande wants a '' growth pact '' in Europe - a set of reforms designed to boost European economies and mitigate the pain caused by government spending cuts across the continent .",
          "text": "The new French President Francois Hollande",
          "namedEntityTypes": ["PEOPLE"]
        }, {
          "head": "area",
          "headIndex": 7,
          "start": 6,
          "end": 15,
          "sentence": "The three lifeboats have been searching an area 25 miles ( 40km ) south of Wick , in the Beatrice oil field , for the two crew who remain missing .",
          "sentenceHtml": "The three lifeboats have been searching an area 25 miles ( 40km ) south of Wick , in the Beatrice oil field , for the two crew who remain missing .",
          "text": "an area 25 miles ( 40km ) south of Wick",
          "namedEntityTypes": ["LOCATION"]
        }, {
          "head": "Co-op",
          "headIndex": 1,
          "start": 0,
          "end": 1,
          "sentence": "The Co-op will pay GBP350m upfront and up to an additional # 400m based on the performance of the combined business .",
          "sentenceHtml": "The Co-op will pay GBP350m upfront and up to an additional # 400m based on the performance of the combined business .",
          "text": "The Co-op",
          "namedEntityTypes": ["ORGANISATION"]
        }, {
          "head": "shares",
          "headIndex": 31,
          "start": 30,
          "end": 31,
          "sentence": "The resolution for change was filed by Christian Brothers Investment Services ( CBIS ) and members of the Local Authority Pension Fund Forum ( LAPFF ) , organizations that own B shares .",
          "sentenceHtml": "The resolution for change was filed by Christian Brothers Investment Services ( CBIS ) and members of the Local Authority Pension Fund Forum ( LAPFF ) , organizations that own B shares .",
          "text": "B shares",
          "namedEntityTypes": ["MONEY"]
        }]


## Part-of-Speech Tagging [/postag]
This service assigns word class types to individual words in the text snippet.
The [tagset]() used is largely compatible with the [Penn Treebank Tagset](http://www.cis.upenn.edu/~treebank/).

### Words [POST]

+ Attributes (object)

    + text: I might buy a MacBookPro. (string, required) - The text that you want to analyse.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "posTag": "PRP",
          "posTaggedWord": "I/PRP",
          "sentenceIndex": 0,
          "stem": "I|i",
          "text": "I",
          "wordIndex": 0
        }, {
          "posTag": "MD",
          "posTaggedWord": "might/MD",
          "sentenceIndex": 0,
          "stem": "might|may",
          "text": "might",
          "wordIndex": 1
        }, {
          "posTag": "VB",
          "posTaggedWord": "buy/VB",
          "sentenceIndex": 0,
          "stem": "buy",
          "text": "buy",
          "wordIndex": 2
        }, {
          "posTag": "DT",
          "posTaggedWord": "a/DT",
          "sentenceIndex": 0,
          "stem": "a",
          "text": "a",
          "wordIndex": 3
        }, {
          "posTag": "NNP",
          "posTaggedWord": "MacBookPro/NNP",
          "sentenceIndex": 0,
          "stem": "MacBookPro|macbookpro",
          "text": "MacBookPro",
          "wordIndex": 4
        }, {
          "posTag": ".",
          "posTaggedWord": "./.",
          "sentenceIndex": 0,
          "stem": ".",
          "text": ".",
          "wordIndex": 5
        }]


## Phrase Chunking [/chunkparse]
This service detects the boundaries of basic shallow syntactic phrases in the text snippet.
For each sentence, simple non-recursive Noun Phrase (NP) and Verb Group (VG) constituents are provided.

### Noun Phrases and Verb Groups [POST]

+ Attributes (object)

    + text: The latest patch will probably solve all your problems. (string, required) - The text that you want to analyse.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "chunk": {
            "chunkType": "",
            "end": 0,
            "sentenceIndex": 0,
            "start": 0,
            "text": "The"
          },
          "head": {
            "posTag": "DT",
            "posTaggedWord": "The/DT",
            "stem": "The",
            "text": "The",
            "wordIndex": 0
          }
        }, {
          "chunk": {
            "chunkType": "",
            "end": 1,
            "sentenceIndex": 0,
            "start": 1,
            "text": "latest"
          },
          "head": {
            "posTag": "JJS",
            "posTaggedWord": "latest/JJS",
            "stem": "late",
            "text": "latest",
            "wordIndex": 1
          }
        }, {
          "chunk": {
            "chunkType": "NP",
            "end": 2,
             "sentenceIndex": 0,
            "start": 0,
            "text": "The latest patch"
          },
          "head": {
            "posTag": "NN",
            "posTaggedWord": "patch/NN",
            "stem": "patch",
            "text": "patch",
            "wordIndex": 2
          }
        }, {
          "chunk": {
            "chunkType": "",
            "end": 3,
            "sentenceIndex": 0,
            "start": 3,
            "text": "will"
          },
          "head": {
            "posTag": "MD",
            "posTaggedWord": "will/MD",
            "stem": "will",
            "text": "will",
            "wordIndex": 3
          }
        }, {
          "chunk": {
            "chunkType": "",
            "end": 4,
            "sentenceIndex": 0,
            "start": 4,
            "text": "probably"
          },
          "head": {
            "posTag": "RB",
            "posTaggedWord": "probably/RB",
            "stem": "probably",
            "text": "probably",
            "wordIndex": 4
          }
        }, {
          "chunk": {
            "chunkType": "VP",
            "end": 5,
            "sentenceIndex": 0,
            "start": 3,
            "text": "will probably solve"
          },
          "head": {
            "posTag": "VB",
            "posTaggedWord": "solve/VB",
            "stem": "solve",
            "text": "solve",
            "wordIndex": 5
          }
        }, {
          "chunk": {
            "chunkType": "",
            "end": 6,
            "sentenceIndex": 0,
            "start": 6,
            "text": "all"
          },
          "head": {
            "posTag": "PDT",
            "posTaggedWord": "all/PDT",
            "stem": "all",
            "text": "all",
            "wordIndex": 6
          }
        }, {
          "chunk": {
            "chunkType": "",
            "end": 7,
            "sentenceIndex": 0,
            "start": 7,
            "text": "your"
          },
          "head": {
            "posTag": "PRP$",
            "posTaggedWord": "your/PRP$",
            "stem": "your",
            "text": "your",
            "wordIndex": 7
          }
        }, {
          "chunk": {
            "chunkType": "NP",
            "end": 8,
            "sentenceIndex": 0,
            "start": 6,
            "text": "all your problems"
          },
          "head": {
            "posTag": "NNS",
            "posTaggedWord": "problems/NNS",
            "stem": "problem",
            "text": "problems",
            "wordIndex": 8
          }
        }, {
          "chunk": {
            "chunkType": "",
            "end": 9,
            "sentenceIndex": 0,
            "start": 9,
            "text": "."
          },
          "head": {
            "posTag": ".",
            "posTaggedWord": "./.",
            "stem": ".",
            "text": ".",
            "wordIndex": 9
          }
        }]


## Dependency Parsing [/depparse]
This service analyses the grammatical structure of each sentence in the text snippet.
For each sentence, typed syntactic dependencies between individual words are provided.
The parses and the [typed dependencies]() used resemble the labels and types described in the [Cambridge Grammar of the English Language](http://www.cambridge.org/uk/linguistics/cgel/).

### Syntactic Dependencies [POST]

+ Attributes (object)

    + text: I got a new camera which takes brilliant photos. (string, required) - The text that you want to analyse.
    
+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
            "dependency": {
              "predicate": "nsubj(got, I)",
              "relation": "nsubj"
            },
            "dependent": {
              "text": "I",
              "stem": "I|i",
              "wordIndex": 0
            },
            "governor": {
              "text": "got",
              "stem": "got|get",
              "wordIndex": 1
            }
        }, {
            "dependency": {
              "predicate": "(root, got)",
              "relation": ""
            },
            "dependent": {
              "text": "got",
              "stem": "got|get",
              "wordIndex": 1
            }
            }, {
            "dependency": {
              "predicate": "det(camera, a)",
              "relation": "det"
            },
            "dependent": {
              "text": "a",
              "stem": "a",
              "wordIndex": 2
            },
            "governor": {
              "text": "camera",
              "stem": "camera",
              "wordIndex": 4
            }
        }, {
            "dependency": {
              "predicate": "amod(camera, new)",
              "relation": "amod"
            },
            "dependent": {
              "text": "new",
              "stem": "new",
              "wordIndex": 3
            },
            "governor": {
              "text": "camera",
              "stem": "camera",
              "wordIndex": 4
            }
        }, {
            "dependency": {
              "predicate": "dobj(got, camera)",
              "relation": "dobj"
            },
            "dependent": {
              "text": "camera",
              "stem": "camera",
              "wordIndex": 4
            },
            "governor": {
              "text": "got",
              "stem": "got|get",
              "wordIndex": 1
            }
        }, {
            "dependency": {
              "predicate": "rel(takes, which)",
              "relation": "rel"
            },
            "dependent": {
              "text": "which",
              "stem": "which",
              "wordIndex": 5
            },
            "governor": {
              "text": "takes",
              "stem": "takes|take",
              "wordIndex": 6
            }
        }, {
            "dependency": {
              "predicate": "rcmod(camera, takes)",
              "relation": "rcmod"
            },
            "dependent": {
              "text": "takes",
              "stem": "takes|take",
              "wordIndex": 6
            },
            "governor": {
              "text": "camera",
              "stem": "camera",
              "wordIndex": 4
            }
        }, {
            "dependency": {
              "predicate": "amod(photos, brilliant)",
              "relation": "amod"
            },
            "dependent": {
              "text": "brilliant",
              "stem": "brilliant",
              "wordIndex": 7
            },
            "governor": {
              "text": "photos",
              "stem": "photos|photo",
              "wordIndex": 8
            }
        }, {
            "dependency": {
              "predicate": "dobj(takes, photos)",
              "relation": "dobj"
            },
            "dependent": {
              "text": "photos",
              "stem": "photos|photo",
              "wordIndex": 8
            },
            "governor": {
              "text": "takes",
              "stem": "takes|take",
              "wordIndex": 6
            }
        }, {
            "dependency": {
              "predicate": "(root, .)",
              "relation": ""
            },
            "dependent": {
              "text": ".",
              "stem": ".",
              "wordIndex": 9
          }
        }]


## Text Summarisation [/summary]

This service generates a summary from the input text. The summary consists of sentences delimited by `\n`.

### Summaries [POST]

+ Attributes (object)

    + text: ...your...text... (string, required) - The text that you want to summarise.
    + ratio: `0.6` (number, optional) - The size of the summary (i.e. the proportion of the full input text) that is included in the summary. The range is 0 ≤ ratio ≤ 1.0 where 0 returns all sentences and 1.0 includes only the most salient sentence(s) in the input text.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        [{
          "summary": "Charities criticise UK for ending humanitarian aid\nCharities have criticised the UK after the govt announced it would stop direct aid to Peru in 2019.\n UK ministers said their relationship with Peru is more about trade and not development as such."
        }]


## Language Detection [/langdetect]

This service returns an [ISO 639-1](http://www.loc.gov/standards/iso639-2/php/code_list.php) natural language code for the input text.

### Language Codes [POST]

+ Attributes (object)

    + text: To be or not to be (string, required) - The text for which you want a language code.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 200 (application/json)

        {
          "iso6391": "en"
        }


## Resources for Sentiment Analysis [/resources/lexicons/sentiment]

This end point allows you to manage the lexical resources that are used in the sentiment analysis on your account.
By fine-tuning and customising word lists (adjectives, adverbs, nouns, verbs), you can adapt the sentiment analysis to a particular genre, domain, topic, or use case beyond the default generic resources.

### Uploading a Lexicon Entry [POST /resources/lexicons/sentiment/{lexicon}]

+ Parameters
    + lexicon (enum[string])
    
        Sentiment lexicon name

        + Members
            + `adjectives`
            + `adverbs`
            + `nouns`
            + `verbs`

+ Attributes (object)

    + text: `quasicool` (string, required) - The entry to be stored in the lexicon.
    + polarity: `pos` (string, required) - Sentiment polarity p of the lexicon entry where p ∈ { pos | ntr | neg }.
    + reverse: `equ` (string, required) - Sentiment reversal r of the lexicon entry where r ∈ { rev | equ }.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 201

### Viewing Lexicon Entries [GET /resources/lexicons/sentiment/{lexicon}]

+ Parameters
    + lexicon (enum[string])
    
        Sentiment lexicon name

        + Members
            + `adjectives`
            + `adverbs`
            + `nouns`
            + `verbs`
    
+ Response 200 (application/json)

        [{
          "text": "quasi-intelligent",
          "polarity": "pos",
          "id": "51b0630a7a233d39005ecc1e"
        }, {
          "text": "unemployment",
          "polarity": "ntr",
          "id": "51b0630a7a233d39005ecc1e"
        }]

### Viewing a Lexicon Entry [GET /resources/lexicons/sentiment/{lexicon}/{objectID}]

+ Parameters
    + lexicon (enum[string])
    
        Sentiment lexicon name

        + Members
            + `adjectives`
            + `adverbs`
            + `nouns`
            + `verbs`
    
    + objectID (string) - Unique ID of a lexicon entry

+ Response 200 (application/json)

        {
          "text": "quasi-intelligent",
          "polarity": "pos",
          "id": "51b0630a7a233d39005ecc1e"
        }

### Deleting a Lexicon Entry [DELETE /resources/lexicons/sentiment/{lexicon}/{objectID}]

+ Parameters
    + lexicon (enum[string])
    
        Sentiment lexicon name

        + Members
            + `adjectives`
            + `adverbs`
            + `nouns`
            + `verbs`
    
    + objectID (string) - Unique ID of a lexicon entry

+ Response 200 (application/json)

## Resources for Entity Taxonomies [/resources/taxonomies/entity]

This end point allows you to manage the taxonomic resources that are used in the entity categorisation on your account.
By adding pattern matching rules for taxonomic categories, you can categorise entity mentions into any desired taxonomic levels beyond the default head noun-based grouping.

### Uploading a Taxonomy Entry [POST /resources/taxonomies/entity]

+ Attributes (object)

    + matchPattern: `(price(s)?|bill(s)?|offer(s)?|expensive|rip(-| )?off)` (string, required) - A regex pattern for capturing entity mentions.
    + category: `PRICE` (string, required) - The taxonomic category under which matched entity mentions should be categorised.
    
+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 201

### Viewing a Taxonomy Entry [GET /resources/taxonomies/entities]

+ Response 200 (application/json)

        [{
          "matchPattern": "pizza(s)?",
          "category": "FOOD.PIZZA",
          "id": "51b0780a7a233d4e005ecc1f"
        }, {
          "matchPattern": "(beer|lager|bitter)",
          "category": "FOOD.DRINK",
          "id": "51b0781f7a233d48005ecc20"
        }]

### Viewing a Taxonomy Entry [GET /resources/taxonomies/entities/{objectID}]

+ Parameters

    + objectID (string) - Unique ID of a taxonomy entry
    
+ Response 200 (application/json)

        {
          "matchPattern": "(beer|lager|bitter)",
          "category": "FOOD.DRINK",
          "id": "51b0781f7a233d48005ecc20"
        }

### Deleting a Taxonomy Entry [DELETE /resources/taxonomies/entities/{objectID}]

+ Parameters

    + objectID (string) - Unique ID of a taxonomy entry 

+ Response 200 (application/json)


## Feedback [/feedback]

`AVAILABLE SOON!`

If you spot 1) incorrect, odd, or funny analyses (classifications, predictions, tags, chunks, parses, labels, ranges, values and the like), 2) structural anomalies or defects, or 3) general issues in the responses returned by the API, you can submit free-form feedback to us which we will look into.
Your feedback is greatly appreciated!

### Submission [POST]

+ Attributes (object)

    + endpoint: sentiment (string, required) - The name of the service end point that returned the response that you want to report.
    + expected: positive (string, optional) - The correct or expected value(s) that the response should have contained.
    + feedback: Funny analysis, really! (string, required) - Any detailed information or general comments that you can provide that will help us diagnose the issue.
    + text: I have a love/hate relationship with Marmite. (string, required) - The data in the `text` field that you used in the request that was sent to end point in question.

+ Request
    + Headers

            Content-Type: application/json; charset=UTF-8

+ Response 201


## Account Usage [/usagestats]

You can monitor your API usage within a specific time period between two time stamps.
The timestamps expect values that are compliant with the [W3C](http://www.w3.org/TR/NOTE-datetime) date and time format.

### Statistics [GET]

+ Parameters
    + from: `2013-02-01` (string, required) - The [W3C](http://www.w3.org/TR/NOTE-datetime) start value for the query.
    + to: `2013-02-13` (string, optional) - The [W3C](http://www.w3.org/TR/NOTE-datetime) end value for the query. If omitted, defaults to `now`.
    + groupby: `date` (string, optional) - Specify the fields to group the results by. Possible values: `date`, `method`, `path`, `status`, `ip`. These can be combined as a comma separated list, e.g. `groupby=date,ip`. The `all` value can be used a shorthand. Defaults to `date`.
    + aggregate: `duration` (string, optional) - Specify the aggregates. Possible values `count`, `length`, `duration`. These can be combined as a comma separated list, e.g. `aggregate=length,duration`. The `all` value can be used a shorthand. Defaults to `count`.

+ Response 200 (application/json)

        {
          "username": "yourUserName",
          "from": "2013-02-06T00:00:00.000Z",
          "to": "2013-02-13T00:00:00.000Z",
          "requestCount": 193,
          "dailyUsage": [{
              "date": "2013-02-06T00:00:00.000Z",
              "requestCount": 0
            }, {
              "date": "2013-02-07T00:00:00.000Z",
              "requestCount": 3
            }, {
              "date": "2013-02-08T00:00:00.000Z",
              "requestCount": 97
            }, {
              "date": "2013-02-09T00:00:00.000Z",
              "requestCount": 0
            }, {
              "date": "2013-02-10T00:00:00.000Z",
              "requestCount": 0
            }, {
              "date": "2013-02-11T00:00:00.000Z",
              "requestCount": 15
            }, {
              "date": "2013-02-12T00:00:00.000Z",
              "requestCount": 72
            }, {
              "date": "2013-02-13T00:00:00.000Z",
              "requestCount": 6
            }
          ]
        }
